{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import imghdr\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "from _lib_.undistort import camera\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project_video = \"./project_video.mp4\"\n",
    "clb_path = \"./camera_cal\"\n",
    "test_path = \"./test_images\"\n",
    "out_path = \"./output_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration and Fix Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = 5\n",
    "chessboard_fs = [os.path.join(clb_path, f) for f in sorted(os.listdir(clb_path))[:samples]]\n",
    "print(chessboard_fs)\n",
    "chessboards = [cv2.imread(f) for f in chessboard_fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cam = camera(clb_path, 9, 6)\n",
    "undst_chessboards = [cam.cal_undist(cb) for cb in chessboards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"distort and undisort images\")\n",
    "plt.rcParams['figure.figsize'] = (samples, 8)\n",
    "fig, axes = plt.subplots(samples, 2)\n",
    "for i in range(samples):\n",
    "    axes[i][0].imshow(chessboards[i])\n",
    "    axes[i][1].imshow(undst_chessboards[i])\n",
    "    axes[i][0].axis('off')\n",
    "    axes[i][1].axis('off')\n",
    "    f = os.path.join(out_path, clb_path[2:], (\"undist_calibration%02d.jpg\"%(i+1)))\n",
    "    cv2.imwrite(f, undst_chessboards[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corrected_video = 'corrected.mp4'\n",
    "clip = VideoFileClip(project_video)\n",
    "video = clip.fl_image(cam.cal_undist)\n",
    "%time video.write_videofile(corrected_video, audio = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width = \"720\" height = \"405\" controls>\n",
    "<source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(corrected_video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame = clip.get_frame(3.78)\n",
    "frame_corrected = video.get_frame(3.78)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 20, 5\n",
    "plt.subplot(121)\n",
    "plt.imshow(frame)\n",
    "plt.subplot(122)\n",
    "plt.imshow(frame_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_imgfs = os.listdir(test_path)\n",
    "n_test = len(test_imgfs)\n",
    "test_out = os.path.join(out_path, \"undist_test_images\")\n",
    "for imgf in test_imgfs:\n",
    "    img = cv2.imread(os.path.join(test_path, imgf))\n",
    "    corrected_img = cam.cal_undist(img)\n",
    "    cv2.imwrite(os.path.join(test_out, (\"undist_%s\"%imgf)), corrected_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Selection And Color Space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(n_test, 3, figsize = (15, n_test * 3))\n",
    "fig.tight_layout()\n",
    "for i, imgf in enumerate(test_imgfs):\n",
    "    img = cv2.imread(os.path.join(test_path, imgf))\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    axes[i][0].imshow(hls[:,:,0], cmap = 'gray')\n",
    "    axes[i][1].imshow(hls[:,:,1], cmap = 'gray')\n",
    "    axes[i][2].imshow(hls[:,:,2], cmap = 'gray')\n",
    "    for j in range(3):\n",
    "        axes[i][j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def select_color(im, l_thresh, s_thresh):\n",
    "    img = np.copy(im)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS).astype(np.float)\n",
    "    h = hls[:,:,0]\n",
    "    s = hls[:,:,2]\n",
    "    mask = np.zeros_like(img[:,:,0])\n",
    "    mask[(s >= s_thresh[0]) & (s <= s_thresh[1]) &\n",
    "         (h >= l_thresh[0]) & (h <= l_thresh[1])] = 1\n",
    "    return mask.astype(np.float32)\n",
    "\n",
    "fig, axes = plt.subplots(n_test, 2, figsize = (10, n_test * 3))\n",
    "fig.tight_layout()\n",
    "plt.rcParams['figure.figsize'] = (2*n_test, 16)\n",
    "for i, imgf in enumerate(test_imgfs):\n",
    "    img = cv2.imread(os.path.join(test_path, imgf))\n",
    "    axes[i][0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axes[i][1].imshow(\n",
    "        select_color(img, l_thresh = (0, 100), s_thresh = (90, 255)),\n",
    "        cmap = 'gray')\n",
    "    axes[i][0].axis('off')\n",
    "    axes[i][1].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, sobel_kernel = 3, orient = 'x', thresh = (0, 255)):\n",
    "    ch = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    x, y = int(orient is 'x'), int(orient is 'y')\n",
    "    assert x + y == 1, \"orientation should be 'x' or 'y'\"\n",
    "    abs_sobel = np.absolute(cv2.Sobel(ch, cv2.CV_64F, x, y, ksize = sobel_kernel))\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    mask = np.zeros_like(scaled_sobel)\n",
    "    mask[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return mask.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mag_sobel_thresh(img, sobel_kernel = 3, thresh = (0, 255)):\n",
    "    ch = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sobelx = cv2.Sobel(ch, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(ch, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "    sobel_mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    mask = np.zeros_like(sobel_mag)\n",
    "    mask[(sobel_mag >= thresh[0]) & (sobel_mag <= thresh[1])] = 1    \n",
    "    return mask.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dir_sobel_thresh(img, sobel_kernel = 3, thresh = (0, np.pi/2)):\n",
    "    ch = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sobelx = np.absolute(cv2.Sobel(ch, cv2.CV_64F, 1, 0, ksize = sobel_kernel))\n",
    "    sobely = np.absolute(cv2.Sobel(ch, cv2.CV_64F, 0, 1, ksize = sobel_kernel))\n",
    "    sobel_dir = np.arctan2(sobely, sobelx)\n",
    "    mask = np.zeros_like(sobel_dir)\n",
    "    mask[(sobel_dir >= thresh[0]) & (sobel_dir <= thresh[1])] = 1    \n",
    "    return mask.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(n_test, 2, figsize = (10, n_test * 3))\n",
    "fig.tight_layout()\n",
    "for i, imgf in enumerate(test_imgfs):\n",
    "    img = cv2.imread(os.path.join(test_path, imgf))\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS).astype(np.float)\n",
    "    s = hls[:,:,2]\n",
    "    axes[i][0].imshow(s,cmap = 'gray')\n",
    "    axes[i][1].imshow(abs_sobel_thresh(img, sobel_kernel = 3, thresh = (25, 255)),\n",
    "        cmap = 'gray')\n",
    "    axes[i][0].axis('off')\n",
    "    axes[i][1].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(n_test, 2, figsize = (10, n_test * 3))\n",
    "fig.tight_layout()\n",
    "for i, imgf in enumerate(test_imgfs):\n",
    "    img = cv2.imread(os.path.join(test_path, imgf))\n",
    "    axes[i][0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    mask_gradient = abs_sobel_thresh(img, sobel_kernel = 3, thresh = (25, 255))\n",
    "    mask_color = select_color(img, l_thresh = (0, 100), s_thresh = (90, 255))\n",
    "    mask = np.dstack((np.zeros_like(img[:,:,0]), mask_gradient, mask_color))\n",
    "    axes[i][1].imshow(mask)\n",
    "    for j in range(2):\n",
    "        axes[i][j].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "standard_img = cv2.imread(os.path.join(test_path, test_imgfs[3]))\n",
    "standard_img = cv2.cvtColor(standard_img, cv2.COLOR_BGR2RGB)\n",
    "plt.rcParams['figure.figsize'] = (20, 40)\n",
    "\n",
    "src = np.float32([[225, 710], [1095, 710], [545, 485], [745, 485]])\n",
    "\n",
    "green = (0, 255, 0)\n",
    "check = np.copy(standard_img)\n",
    "for p in src:\n",
    "    cv2.circle(check, tuple(p), 8, green, -5)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(standard_img)\n",
    "plt.subplot(122)\n",
    "plt.imshow(check)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dst = np.float32([[225, 710], [1095, 710], [225, 460], [1095, 460]])\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "h, w, _ = standard_img.shape\n",
    "warped = cv2.warpPerspective(standard_img, M, (w, h), flags = cv2.INTER_LINEAR)\n",
    "plt.imshow(warped)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(n_test, 2, figsize = (10, n_test * 3))\n",
    "fig.tight_layout()\n",
    "for i, imgf in enumerate(test_imgfs):\n",
    "    img = cv2.imread(os.path.join(test_path, imgf))\n",
    "    axes[i][0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    warped = cv2.warpPerspective(img, M, (w, h), flags = cv2.INTER_LINEAR)\n",
    "    mask_gradient = mag_sobel_thresh(warped, sobel_kernel = 15, thresh = (30, 255))\n",
    "    mask_color = select_color(warped, l_thresh = (0, 90), s_thresh = (90, 255))\n",
    "    mask = np.uint8(mask_gradient) + np.uint8(mask_color)\n",
    "    #mask = np.dstack((np.zeros_like(img[:,:,0]), mask_gradient, mask_color))\n",
    "    #warped = cv2.warpPerspective(mask, M, (w, h), flags = cv2.INTER_LINEAR)\n",
    "    axes[i][1].imshow(mask, cmap = 'gray')\n",
    "    for j in range(2):\n",
    "        axes[i][j].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dev_pipeline(img):\n",
    "    undist = cam.cal_undist(img)\n",
    "    warped = cv2.warpPerspective(undist, M, (w, h), flags = cv2.INTER_LINEAR)\n",
    "    mask_gradient = abs_sobel_thresh(warped, sobel_kernel = 3, thresh = (25, 255))\n",
    "    mask_color = select_color(warped, l_thresh = (0, 100), s_thresh = (90, 255))\n",
    "    mask = mask_gradient + mask_color\n",
    "    return np.tile(mask.reshape([h, w, 1]), (1, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame = clip.get_frame(3.78)\n",
    "warped = dev_pipeline(frame)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 20, 5\n",
    "plt.subplot(121)\n",
    "plt.imshow(frame)\n",
    "plt.subplot(122)\n",
    "plt.imshow(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lane = 'lane.mp4'\n",
    "clip_lane = VideoFileClip(project_video)\n",
    "video = clip_lane.fl_image(dev_pipeline)\n",
    "%time video.write_videofile(lane, audio = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width = \"720\" height = \"405\" controls>\n",
    "<source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(lane))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
